{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons nous intéresser dans ce cours à la matrice de covariance d'un groupe de points, et voir comment refaire l'exercice de la régression linéaire avec une approche différente, qui repose sur le principe de la réduction de dimension.\n",
    "\n",
    "Avant d'aller plus loin, on génère notre nuage de points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params  = (0,10)\n",
    "var = 5\n",
    "N = 100\n",
    "x = #random entre 0 et 10\n",
    "y = #a*x+b+var*N(0,1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous disposons d'un jeu de données écrit sous la forme suivante :\n",
    "\n",
    "$$X = \\left[ \\begin{array}{c} X_1 \\\\ X_2 \\\\ \\vdots \\end{array} \\right]$$\n",
    "\n",
    "La matrice de covariance est la matrice avec les entrées suivantes\n",
    "\n",
    "$$ \\sigma_{ij} = \\frac {1}{N-1} \\sum_{k=1}^N (X_{ki}-\\bar X_i) (X_{kj} - \\bar X_j)$$\n",
    "\n",
    "A quoi correspondent les entrées diagonales ?\n",
    "A quoi ressemble cette matrice dans notre cas ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def covariance(x,y):\n",
    "    pass \n",
    "\n",
    "def Matrice_covariance_2D(x,y):\n",
    "    pass\n",
    "\n",
    "M = Matrice_covariance_2D(x,y)\n",
    "np.testing.assert_almost_equal(M, np.cov(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices et géométrie\n",
    "\n",
    "Une matrice est une application linéaire. La matrice de covariance est une matrice symétrique qui peut être interprétée comme un endormorphisme sur un espace vectoriel, correspondant aux vecteurs des données.\n",
    "\n",
    "Nous allons interpréter géométriquement cette matrice. Si vous n'avez pas d'intuition sur les matrices, vous pouvez allez sur le lien suivant : http://ncase.me/matrix/\n",
    "\n",
    "### Matrice de rotation\n",
    "Un exemple connu de matrice sont les matrices de rotation. Pour un vecteur à 2 dimension, elles s'écrivent sous la forme\n",
    "\n",
    "$$ R(\\theta) =  \\begin{pmatrix}  \\cos \\theta & - \\sin \\theta \\\\ \\sin \\theta & \\cos \\theta \\end{pmatrix} $$\n",
    "\n",
    "Ces matrices sont orthogonales $R^T = R^{-1}$, de sorte qu'elles conservent la norme des vecteurs, et leur déterminant vaut 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u = np.array([1,0])\n",
    "\n",
    "def rotation_matrix(theta):\n",
    "    from math import cos, sin\n",
    "    pass\n",
    "\n",
    "def rotate(v, theta):\n",
    "    pass\n",
    "\n",
    "u_prime = rotate(u, 3.14159/2) #rotation de u de 90°\n",
    "\n",
    "assert np.linalg.norm(u) == np.linalg.norm(u_prime)\n",
    "assert np.linalg.det(rotation_matrix(3*14159/2)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(u[0], u[1], color=\"blue\")\n",
    "plt.scatter(u_prime[0], u_prime[1], color=\"red\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Géométrie de la matrice de covariance\n",
    "\n",
    "Afin de mieux comprendre cette matrice, nous allons d'abord générer un nuage de points totalement aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u = 10*np.random.random(N)\n",
    "v = 10*np.random.random(N)\n",
    "\n",
    "plt.scatter(u,v)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UV = np.dot(M, np.vstack((u,v)))\n",
    "plt.scatter(UV[0], UV[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de correlation calculée depuis nos x et y initiaux à transformer u, v en les alignant sur un axe particulier, qui semble correspondre à la relation entre x et y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valeurs propres et vecteurs propres\n",
    "\n",
    "La matrice semble avoir une direction privilégiée. Que peut-on apprendre à partir des valeurs et vecteurs propres ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eig_val, eig_vec = np.linalg.eig(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print 'à la valeur propre', eig_val[i], 'correspond le vecteur', eig_vec[:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons nous intéresser au vecteur dont la valeur propre est la plus élevée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "principal_v = eig_vec[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calcul du coefficient de la droite\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons retrouver, simplement par l'analyse de la matrice de covariance, le coefficient de la droite qui explique le nuage de points initial x et y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration avec Iris\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "150 fleurs iris de 3 espèces différentes.\n",
    "\n",
    "Les données se composent de :\n",
    "1. sepal length in cm \n",
    "2. sepal width in cm \n",
    "3. petal length in cm \n",
    "4. petal width in cm \n",
    "5. class:   \n",
    "-- Iris Setosa    \n",
    "-- Iris Versicolour   \n",
    "-- Iris Virginica   \n",
    "\n",
    "Nous allons utiliser la librairie pandas pour plus de simplicité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('iris.data', header=None, sep=',')\n",
    "df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons facilement séparer les colonnes en utilisant les noms que nous avons défini plus haut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid']]\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisons le module PCA de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_fit = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut rapidement voir que nous sommes bien passés à un espace réduit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape[1]\n",
    "print X_fit.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'avantage est que nous pouvons maintenant représenter graphiquement les données sur un seul plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_fit[:,0], X_fit[:,1])\n",
    "plt.xlabel(\"composante principale 1\")\n",
    "plt.ylabel(\"composante principale 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutons un peu de couleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "for lab, col in zip(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'),\n",
    "                    ('blue', 'red', 'green')):\n",
    "    plt.scatter(X_fit[np.array(y==lab),0],\n",
    "                X_fit[np.array(y==lab), 1],\n",
    "                label=lab,\n",
    "                c=col)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La PCA est très souvent utilisée en amont d'autres algorithmes pour réduire la compléxité et le bruit dans les données, et pour améliorer les performances de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(X_fit)\n",
    "plt.scatter(X_fit[:, 0], X_fit[:, 1], c=kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(kmeans.labels_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mapping = {'Iris-setosa':0, 'Iris-versicolor':2, 'Iris-virginica':1}\n",
    "confusion_matrix(kmeans.labels_, y.replace(mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(kmeans.labels_, y.replace(mapping)), ['Iris-setosa', 'Iris-virginica', 'Iris-versicolor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
